# Data-Science-Final-Portfolio-Project-Cancer-Type-Prediction
Codecademy Data Science Final Portfolio Project

Your data science portfolio is your secret weapon when applying for potential positions. It should not only show off your skills and experience, but give your interviewers insight into how you tackle data science problems. Your portfolio should highlight how you thought about, worked through, and visualized your results. This project will give you an opportunity to complete the final culminating example project for your portfolio.

For this project, you will conduct your own analysis in a Jupyter Notebook and share your results through your personal GitHub page. This project can be included as part of your portfolio when you apply for data science jobs. It’s good practice to showcase a variety of skills in order to make your application shine.

Example Project

Example Final Portfolio Project

Project Objectives:

Complete a project to add to a portfolio

Use Git version control

Use Jupyter Notebook to communicate findings

Run an end-to-end data science project

Become familiar with data science workflows

Prerequisites:

Natural Language Processing

Supervised Machine Learning

Unsupervised Machine Learning

Deep Learning

Big Data

================================================================================

## 1.Setting up your Git Repository

Create a new Git repository for this project.

If you need more guidance, review the GitHub Desktop article and additional help on this Git cheat sheet.

Main components that you will want to include:

Jupyter Notebook

CSV data file(s)

## 2.Project Scoping

Properly scoping your project will greatly benefit you; scoping creates structure while requiring you to think through your entire project before you begin. You should start with stating the goals for your project, then gathering the data, and considering the analytical steps required. A proper project scope can be a great road map for your project, but keep in mind that some down-stream tasks may become dead ends which will require adjustment to the scope.

Hint:

Here is University of Chicago’s Data Science Project Scoping Guide.

Main components that you will want to include:

Goals

Data

Analysis

## 3.Select Machine Learning Solvable Problem 

First choose a topic of interest; then, within your topic, select a problem that you can answer using a machine learning approach. Make sure that this problem can be solved in a reasonable amount of time and with available data. If the problem is too complex, it might be worth breaking it down into smaller units.

Hint:

Here is a Google Guide for identifying good problems for ML.

Main components that you will want to include:

Topic eg. Natural Conservation

Problem eg. Protecting native species of trees in California

How ML will be used eg. Classify tree species type from satellite imagery.

## 4.Collect Data 

If you didn’t already have a dataset in mind, search the internet and see if it’s freely available. If data is not available, go back to the previous step and find a new problem that will have data readily available.

Hint:

Here are some locations for data.

data.gov: https://www.data.gov/

kaggle: https://www.kaggle.com/datasets?license=cc

data.world: https://data.world/

awesomedata: https://github.com/awesomedata/awesome-public-datasets

Fivethirtyeight: https://data.fivethirtyeight.com/

Buzzfeed: https://github.com/BuzzFeedNews/everything

UCI : https://archive.ics.uci.edu/ml/datasets.php

Main components that you will want to include: Data

## 5.Load and Check Data 

Once you obtain your data, check to see if the data has the right unit of observation (https://en.wikipedia.org/wiki/Unit_of_observation) or granularity. If supervised learning will be used, check that the data has a label or response variable. If the data does not come in the right level of observation or is missing a crucial piece for analysis, go back to the previous step to search for more data, or go back two steps and select a different problem to solve.

Hint:

If you are looking at individuals, but your data is aggregated to 5 year age groups, you’ll need to find different data with individuals or select a different problem. Another example is satellite imagery that has a 30 meter resolution, but the trees that you are trying to classify will not be able to be distinguished with that resolution.

Main components that you will want to include:

Data with proper units

Data with proper variables

## 6.Explore and Explain Data

Once you have obtained your data, it’s a good idea to get acquainted with it. You should show some summary statistics and visually examine your data. Don’t forget to write out some insights that you have gained along with your analysis.

Hint:

Here is the National Institute of Standards and Technology’s (NIST) EDA Introduction :

https://www.itl.nist.gov/div898/handbook/eda/section1/eda11.htm

Main components that you will want to include:

Descriptive statistics like mean, median, range, correlations

Data visualizations for univariate and multivariate exploration

Text explaining insights gained from exploration

## 7.Preprocess Data

Once you have a good understanding of your data, it is time to get it prepared for modeling. These steps can involve joining data, standardizing variables, removing variables, imputation, and splitting data in to train and test sets.

Hint:

Here are some resources to get you started

Standardization

Reshaping

Merge and joining

Splitting data

Tidy data

Main components that you will want to include:

Data ready for modeling

## 8.Make Model(s)

Once the data is preprocessed, it is ready to model. Select the appropriate type(s) of models to solve your problem. Once you have your models, run your data through each model and store your results.

Check out the models that are available on scikit learn:

Supervised learning models

Unsupervised learning models

Main components that you will want to include:

List of models

Outputs from models

## 9.Evaluate Model(s)

Once the model(s) are created, you need to use the metric of success that was defined to evaluate the model performance(s). If you aren’t satisfied with your results you can repeat the previous step.

Hint:

Some models can be tuned, so if you used default inputs it might be good to take what you learned and redo some of the models.

Here are some reference materials:

Model selection and evaluation

Difference between test and validation datasets : https://machinelearningmastery.com/difference-test-validation-datasets/

Main components that you will want to include:

Table showing model performance

Charts showing model performance

## 10.Final Model Selection

Once the best model is selected, a test set can be used to assess the final model. This will be the last analysis step, so make sure that you have created the best model you can for the time being.

Hint:

Main components that you will want to include: Final model you have selected

## 11.Conclusions

Finally we can wrap up the project. You can write a conclusion about your process and findings.

Hint:

Main components that you will want to include:

What did you learn through the process?

Are the results what you expected?

What are the key findings/takeaways?

## 12.Next Steps

Lastly, being a data scientist is about making continual progress. What are future-looking takeaways and limitations? If you were to do this project again, how can you extend this analysis?

Hint:

Main components that you will want to include:

Are there things that should be done differently?

How can this be used in the future?
